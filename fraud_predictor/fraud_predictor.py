import json
import joblib
import pandas as pd
import numpy as np
from kafka import KafkaConsumer, KafkaProducer  # <--- 1. ‡πÄ‡∏û‡∏¥‡πà‡∏° KafkaProducer
import os
import sys
import pickle
import datetime # <--- ‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏™‡πà timestamp

# ==========================================
# 1. SETUP CONFIG
# ==========================================
KAFKA_INPUT_TOPIC = 'fraud.features.ml'     # Topic ‡∏Ç‡∏≤‡πÄ‡∏Ç‡πâ‡∏≤ (Features)
KAFKA_OUTPUT_TOPIC = 'fraud.predictions'    # <--- 2. Topic ‡∏Ç‡∏≤‡∏≠‡∏≠‡∏Å (‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå)
KAFKA_BOOTSTRAP_SERVERS = 'kafka:29092'
MODEL_PATH = 'xgb_model.pkl'
PIPELINE_PATH = 'preprocessing_pipeline.pkl'

# ==========================================
# 2. LOAD RESOURCES
# ==========================================
def load_resources():
    # ... (‡∏™‡πà‡∏ß‡∏ô‡∏ô‡∏µ‡πâ‡πÄ‡∏´‡∏°‡∏∑‡∏≠‡∏ô‡πÄ‡∏î‡∏¥‡∏°) ...
    model = None
    pipeline = None
    if os.path.exists(MODEL_PATH):
        with open(MODEL_PATH, "rb") as f:
            model = pickle.load(f)
            print("‚úÖ XGBoost Model loaded successfully.")
    else:
        print(f"‚ùå Error: Model file not found at {MODEL_PATH}")
        sys.exit(1)

    if os.path.exists(PIPELINE_PATH):
        with open(PIPELINE_PATH, "rb") as f:
            pipeline = pickle.load(f)
            print("‚úÖ Preprocessing Pipeline loaded successfully.")
    else:
        print(f"‚ùå Error: Pipeline file not found at {PIPELINE_PATH}")
        sys.exit(1)
    return model, pipeline

# ==========================================
# 3. FEATURE ENGINEERING
# ==========================================
def feature_engineering(df):
    # ... (‡∏™‡πà‡∏ß‡∏ô‡∏ô‡∏µ‡πâ‡πÄ‡∏´‡∏°‡∏∑‡∏≠‡∏ô‡πÄ‡∏î‡∏¥‡∏°) ...
    df["diffOrig"] = df["oldbalanceOrg"] - df["newbalanceOrig"] - df["amount"]
    df["diffDest"] = df["newbalanceDest"] - df["oldbalanceDest"] - df["amount"]
    df["hour"] = df["step"] % 24
    return df

def prepare_input_dataframe(data):
    # ... (‡∏™‡πà‡∏ß‡∏ô‡∏ô‡∏µ‡πâ‡πÄ‡∏´‡∏°‡∏∑‡∏≠‡∏ô‡πÄ‡∏î‡∏¥‡∏°) ...
    try:
        features = {
            'step': [int(data.get('step', 1))], 
            'type': [str(data.get('type', 'PAYMENT'))],
            'amount': [float(data.get('amount', 0.0))],
            'oldbalanceOrg': [float(data.get('oldbalanceorg', 0.0))],
            'newbalanceOrig': [float(data.get('newbalanceorig', 0.0))],
            'oldbalanceDest': [float(data.get('oldbalancedest', 0.0))],
            'newbalanceDest': [float(data.get('newbalancedest', 0.0))],
        }
        df = pd.DataFrame(features)
        df = feature_engineering(df)
        return df
    except Exception as e:
        print(f"‚ö†Ô∏è Error preparing dataframe: {e}")
        return None

# ==========================================
# 4. MAIN PROCESS
# ==========================================
def main():
    print("üöÄ Fraud Predictor Service Started...")
    
    loaded_model, loaded_pipeline = load_resources()

    # --- SETUP KAFKA PRODUCER (‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÉ‡∏´‡∏°‡πà) ---
    try:
        producer = KafkaProducer(
            bootstrap_servers=KAFKA_BOOTSTRAP_SERVERS,
            value_serializer=lambda v: json.dumps(v).encode('utf-8') # ‡πÅ‡∏õ‡∏•‡∏á Dict ‡πÄ‡∏õ‡πá‡∏ô JSON Bytes ‡∏≠‡∏±‡∏ï‡πÇ‡∏ô‡∏°‡∏±‡∏ï‡∏¥
        )
        print(f"‚úÖ Producer ready for output topic: {KAFKA_OUTPUT_TOPIC}")
    except Exception as e:
        print(f"‚ùå Kafka Producer Connection Failed: {e}")
        return
    # --------------------------------------

    try:
        consumer = KafkaConsumer(
            KAFKA_INPUT_TOPIC,
            bootstrap_servers=KAFKA_BOOTSTRAP_SERVERS,
            auto_offset_reset='latest',
            enable_auto_commit=True,
            group_id='fraud-predictor-group-prod',
            value_deserializer=lambda x: json.loads(x.decode('utf-8'))
        )
        print(f"‚úÖ Consumer connected to input topic: {KAFKA_INPUT_TOPIC}")
    except Exception as e:
        print(f"‚ùå Kafka Consumer Connection Failed: {e}")
        return

    print("Listening for transactions...")

    for message in consumer:
        try:
            transaction_data = message.value
            txn_id = transaction_data.get('id', 'N/A')
            
            # --- Preprocessing ---
            df_input = prepare_input_dataframe(transaction_data)
            if df_input is None: continue

            X_processed = loaded_pipeline.transform(df_input)

            # --- Prediction ---
            prediction = loaded_model.predict(X_processed)[0]
            fraud_prob = loaded_model.predict_proba(X_processed)[0][1]

            result_payload = {
                'transaction_id': txn_id,
                'is_fraud': int(prediction),         
                'risk_score': float(fraud_prob),  
                'timestamp': datetime.datetime.now().isoformat(),
                'model_version': 'XGB v1.0',
                'features': transaction_data
            }

            # --- ‡∏™‡πà‡∏á‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡πÑ‡∏õ Kafka Output Topic ---
            producer.send(KAFKA_OUTPUT_TOPIC, value=result_payload)
            # producer.flush() # ‡πÄ‡∏õ‡∏¥‡∏î‡∏ö‡∏£‡∏£‡∏ó‡∏±‡∏î‡∏ô‡∏µ‡πâ‡∏ñ‡πâ‡∏≤‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡πÉ‡∏´‡πâ‡∏™‡πà‡∏á‡∏ó‡∏±‡∏ô‡∏ó‡∏µ‡∏ó‡∏µ‡∏•‡∏∞‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏° (‡∏à‡∏∞‡∏ä‡πâ‡∏≤‡∏•‡∏á‡∏ô‡∏¥‡∏î‡∏´‡∏ô‡πà‡∏≠‡∏¢)

            # --- Logging ---
            if prediction == 1:
                print(f"üö® FRAUD DETECTED! ID: {txn_id} | Score: {fraud_prob:.2%} -> Sent to Kafka")
            else:
                if fraud_prob > 0.3:
                    print(f"‚ö†Ô∏è Suspicious. ID: {txn_id} | Score: {fraud_prob:.2%} -> Sent to Kafka")
                else:
                    print(f"‚úÖ Normal. ID: {txn_id} | Score: {fraud_prob:.2%} -> Sent to Kafka")

        except Exception as e:
            print(f"‚ùå Processing Error: {e}")

if __name__ == '__main__':
    main()